"""
Local Vulnerability Database
Stores and manages vulnerability data to reduce API calls and improve performance
"""

import json
import os
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import sqlite3
from dataclasses import dataclass, asdict
from enum import Enum

class Severity(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    NONE = "none"

@dataclass
class VulnerabilityRecord:
    cve_id: str
    package_name: str
    version_range: str
    severity: str
    cvss_score: float
    description: str
    references: List[str]
    recommendation: str
    last_updated: str

@dataclass
class PackageVulnerabilitySummary:
    package_name: str
    version: Optional[str]
    risk_score: float
    risk_level: str
    vulnerability_count: int
    vulnerabilities: List[Dict]
    recommendation: str
    last_checked: str

class VulnerabilityDatabase:
    """Local database for storing vulnerability information"""
    
    def __init__(self, db_path: str = "vulnerability_cache.db"):
        self.db_path = db_path
        self.init_database()
        self.load_initial_data()
    
    def init_database(self):
        """Initialize the SQLite database with required tables"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Create vulnerabilities table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerabilities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                cve_id TEXT UNIQUE NOT NULL,
                package_name TEXT NOT NULL,
                version_range TEXT,
                severity TEXT NOT NULL,
                cvss_score REAL,
                description TEXT,
                refs TEXT,
                recommendation TEXT,
                last_updated TEXT NOT NULL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create package_cache table for storing package vulnerability summaries
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS package_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                package_name TEXT NOT NULL,
                version TEXT NOT NULL,
                risk_score REAL NOT NULL,
                risk_level TEXT NOT NULL,
                vulnerability_count INTEGER NOT NULL,
                vulnerabilities TEXT,  -- JSON string
                recommendation TEXT,
                last_checked TEXT NOT NULL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(package_name, version)
            )
        ''')
        
        # Create scan_results table for full scan results
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scan_results (
                scan_id TEXT PRIMARY KEY,
                timestamp TEXT,
                filename TEXT,
                dependencies TEXT,
                subdependencies TEXT,
                vulnerability_count INTEGER,
                vulnerabilities TEXT,
                skipped_dependencies TEXT,
                intelligence_report TEXT,
                user_id TEXT
            )
        ''')
        
        # Create github_enrichment table for storing GitHub repository data
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS github_enrichment (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                scan_id TEXT NOT NULL,
                package_name TEXT NOT NULL,
                platform TEXT,
                repo_path TEXT,
                repo_url TEXT,
                description TEXT,
                stars INTEGER,
                forks INTEGER,
                open_issues INTEGER,
                closed_issues INTEGER,
                language TEXT,
                last_updated TEXT,
                health_data TEXT,  -- JSON string with health assessment
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (scan_id) REFERENCES scan_results(scan_id),
                UNIQUE(scan_id, package_name)
            )
        ''')
        # Add skipped_dependencies column if missing (migration)
        try:
            cursor.execute('ALTER TABLE scan_results ADD COLUMN skipped_dependencies TEXT')
        except Exception:
            pass  # Already exists
        
        # Add filename column if missing (migration)
        try:
            cursor.execute('ALTER TABLE scan_results ADD COLUMN filename TEXT')
        except Exception:
            pass  # Already exists
        
        # Add closed_issues column if missing (migration for improved formulas)
        try:
            cursor.execute('ALTER TABLE github_enrichment ADD COLUMN closed_issues INTEGER DEFAULT 0')
        except Exception:
            pass  # Already exists
        
        # Add package_health_issues column if missing (migration for package health data)
        try:
            cursor.execute('ALTER TABLE scan_results ADD COLUMN package_health_issues TEXT')
        except Exception:
            pass  # Already exists
        
        # Create indexes for better performance
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_package_name ON vulnerabilities(package_name)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_cve_id ON vulnerabilities(cve_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_package_version ON package_cache(package_name, version)')
        
        conn.commit()
        conn.close()
    
    def load_initial_data(self):
        """Load initial vulnerability data for common packages"""
        # Check if we already have data
        if self.get_package_count() > 0:
            return
        
        print("📊 Loading initial vulnerability data...")
        
        # Add some common vulnerabilities we've seen
        initial_vulnerabilities = [
            {
                "cve_id": "CVE-2021-33026",
                "package_name": "Flask",
                "version_range": "None",
                "severity": "critical",
                "cvss_score": 9.8,
                "description": "The Flask-Caching extension through 1.10.1 for Flask relies on Pickle for serialization, which may lead to remote code execution or local privilege escalation.",
                "references": ["https://github.com/pallets-eco/flask-caching/pull/209"],
                "recommendation": "Immediately update Flask to the latest secure version or consider alternative packages."
            },
            {
                "cve_id": "CVE-2022-29361",
                "package_name": "Werkzeug",
                "version_range": "None",
                "severity": "critical",
                "cvss_score": 9.8,
                "description": "Improper parsing of HTTP requests in Pallets Werkzeug v2.1.0 and below allows attackers to perform HTTP request smuggling.",
                "references": ["https://github.com/pallets/werkzeug/security/advisories/GHSA-2m8c-fp4w-j649"],
                "recommendation": "Immediately update Werkzeug to the latest secure version or consider alternative packages."
            },
            {
                "cve_id": "CVE-2019-20477",
                "package_name": "PyYAML",
                "version_range": "5.1,5.1.2",
                "severity": "critical",
                "cvss_score": 9.8,
                "description": "PyYAML 5.1 through 5.1.2 has insufficient restrictions on the load and load_all functions because of Insufficient Control of Network Message Volume.",
                "references": ["https://github.com/yaml/pyyaml/issues/420"],
                "recommendation": "Immediately update PyYAML to the latest secure version or consider alternative packages."
            },
            {
                "cve_id": "CVE-2019-8341",
                "package_name": "Jinja2",
                "version_range": "None",
                "severity": "critical",
                "cvss_score": 9.8,
                "description": "An issue was discovered in Jinja2 2.10. The from_string function is prone to Server Side Template Injection.",
                "references": ["https://github.com/pallets/jinja/security/advisories/GHSA-m583-8m5h-3g2p"],
                "recommendation": "Immediately update Jinja2 to the latest secure version or consider alternative packages."
            }
        ]
        
        for vuln in initial_vulnerabilities:
            self.add_vulnerability(vuln)
        
        print(f"✅ Loaded {len(initial_vulnerabilities)} initial vulnerabilities")
    
    def add_vulnerability(self, vulnerability_data: Dict[str, Any]):
        """Add a vulnerability to the database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO vulnerabilities 
                (cve_id, package_name, version_range, severity, cvss_score, description, refs, recommendation, last_updated)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                vulnerability_data['cve_id'],
                vulnerability_data['package_name'],
                vulnerability_data.get('version_range', ''),
                vulnerability_data['severity'],
                vulnerability_data.get('cvss_score', 0.0),
                vulnerability_data.get('description', ''),
                json.dumps(vulnerability_data.get('references', [])),
                vulnerability_data.get('recommendation', ''),
                datetime.now().isoformat()
            ))
            
            conn.commit()
        except Exception as e:
            print(f"Error adding vulnerability {vulnerability_data['cve_id']}: {e}")
        finally:
            conn.close()
    
    def get_vulnerabilities_for_package(self, package_name: str, version: Optional[str] = None) -> List[Dict]:
        """Get all vulnerabilities for a specific package (case-insensitive)"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT cve_id, package_name, version_range, severity, cvss_score, description, refs, recommendation, last_updated
            FROM vulnerabilities 
            WHERE LOWER(package_name) = LOWER(?)
            ORDER BY cvss_score DESC
        ''', (package_name,))
        
        vulnerabilities = []
        for row in cursor.fetchall():
            vuln = {
                'cve_id': row[0],
                'package_name': row[1],
                'version_range': row[2],
                'severity': row[3],
                'cvss_score': row[4],
                'description': row[5],
                'references': json.loads(row[6]) if row[6] else [],
                'recommendation': row[7],
                'last_updated': row[8]
            }
            vulnerabilities.append(vuln)
        
        conn.close()
        return vulnerabilities
    
    def cache_package_summary(self, package_name: str, version: str, summary: PackageVulnerabilitySummary):
        """Cache a package vulnerability summary"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO package_cache 
                (package_name, version, risk_score, risk_level, vulnerability_count, vulnerabilities, recommendation, last_checked)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                package_name,
                version,
                summary.risk_score,
                summary.risk_level,
                summary.vulnerability_count,
                json.dumps(summary.vulnerabilities),
                summary.recommendation,
                datetime.now().isoformat()
            ))
            
            conn.commit()
        except Exception as e:
            print(f"Error caching package summary for {package_name}: {e}")
        finally:
            conn.close()
    
    def get_cached_package_summary(self, package_name: str, version: Optional[str]) -> Optional[PackageVulnerabilitySummary]:
        """Get cached vulnerability summary for a package (case-insensitive)"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Handle None version
        safe_version = version if version is not None else ''
        
        cursor.execute('''
            SELECT risk_score, risk_level, vulnerability_count, vulnerabilities, recommendation, last_checked
            FROM package_cache 
            WHERE LOWER(package_name) = LOWER(?) AND version = ?
        ''', (package_name, safe_version))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return PackageVulnerabilitySummary(
                package_name=package_name,
                version=version,
                risk_score=row[0],
                risk_level=row[1],
                vulnerability_count=row[2],
                vulnerabilities=json.loads(row[3]) if row[3] else [],
                recommendation=row[4],
                last_checked=row[5]
            )
        
        return None
    
    def is_cache_fresh(self, package_name: str, version: str, max_age_hours: int = 24) -> bool:
        """Check if cached data is fresh (within max_age_hours) - case-insensitive"""
        summary = self.get_cached_package_summary(package_name, version)
        if not summary:
            return False
        
        last_checked = datetime.fromisoformat(summary.last_checked)
        return datetime.now() - last_checked < timedelta(hours=max_age_hours)
    
    def get_package_count(self) -> int:
        """Get total number of packages in cache"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM package_cache')
        count = cursor.fetchone()[0]
        conn.close()
        return count
    
    def get_vulnerability_count(self) -> int:
        """Get total number of vulnerabilities in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM vulnerabilities')
        count = cursor.fetchone()[0]
        conn.close()
        return count
    
    def clear_cache(self):
        """Clear all cached package summaries"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('DELETE FROM package_cache')
        conn.commit()
        conn.close()
        print("🗑️ Cleared vulnerability cache")
    
    def get_database_stats(self) -> Dict[str, Any]:
        """Get statistics about the database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get vulnerability count
        cursor.execute('SELECT COUNT(*) FROM vulnerabilities')
        vuln_count = cursor.fetchone()[0]
        
        # Get package cache count
        cursor.execute('SELECT COUNT(*) FROM package_cache')
        cache_count = cursor.fetchone()[0]
        
        # Get database file size
        file_size = os.path.getsize(str(self.db_path)) if os.path.exists(str(self.db_path)) else 0
        
        conn.close()
        
        return {
            'vulnerability_count': vuln_count,
            'cached_packages': cache_count,
            'database_size_bytes': file_size,
            'database_path': self.db_path
        }
    
    def get_database_path(self) -> str:
        """Get the path to the database file"""
        return self.db_path
    
    def save_scan_result(self, scan_id: str, dependencies: List, subdependencies: List, 
                        vulnerabilities: Dict, skipped_dependencies: List, 
                        user_id: Optional[str] = None, filename: Optional[str] = None, 
                        intelligence_report: Optional[Dict] = None, package_health_data: Optional[Dict] = None):
        """Save complete scan result to database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # Convert SecurityInsight objects to dictionaries if present
            serializable_intelligence_report = None
            if intelligence_report:
                if 'insights' in intelligence_report:
                    # Convert SecurityInsight objects to dictionaries
                    insights = []
                    for insight in intelligence_report['insights']:
                        if hasattr(insight, '__dict__'):
                            # Convert dataclass to dict
                            insights.append({
                                'category': insight.category,
                                'severity': insight.severity,
                                'title': insight.title,
                                'description': insight.description,
                                'affected_packages': insight.affected_packages,
                                'confidence': insight.confidence,
                                'recommendation': insight.recommendation,
                                'technical_details': insight.technical_details
                            })
                        else:
                            # Already a dict
                            insights.append(insight)
                    
                    # Create new intelligence report with serializable insights
                    serializable_intelligence_report = {
                        'threat_level': intelligence_report.get('threat_level'),
                        'insights': insights,
                        'summary_stats': intelligence_report.get('summary_stats'),
                        'recommendations': intelligence_report.get('recommendations')
                    }
                else:
                    serializable_intelligence_report = intelligence_report
            
            cursor.execute('''
                INSERT OR REPLACE INTO scan_results 
                (scan_id, timestamp, filename, dependencies, subdependencies, 
                 vulnerability_count, vulnerabilities, skipped_dependencies, intelligence_report, user_id, package_health_issues)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                scan_id,
                datetime.now().isoformat(),
                filename,
                json.dumps(dependencies),
                json.dumps(subdependencies),
                len(vulnerabilities),
                json.dumps(vulnerabilities),
                json.dumps(skipped_dependencies),
                json.dumps(serializable_intelligence_report) if serializable_intelligence_report else None,
                user_id,
                json.dumps(package_health_data) if package_health_data else None
            ))
            conn.commit()
            print(f"✅ Saved scan result for {scan_id}")
        except Exception as e:
            print(f"❌ Error saving scan result: {e}")
        finally:
            conn.close()

    def get_scan_result_by_id(self, scan_id: str) -> Optional[Dict]:
        """Get a specific scan result by scan_id"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                SELECT scan_id, timestamp, filename, dependencies, subdependencies, 
                       vulnerability_count, vulnerabilities, skipped_dependencies, intelligence_report, user_id, package_health_issues
                FROM scan_results WHERE scan_id = ?
            ''', (scan_id,))
            
            row = cursor.fetchone()
            if row:
                return {
                    'scan_id': row[0],
                    'timestamp': row[1],
                    'filename': row[2],
                    'dependencies': json.loads(row[3]) if row[3] else [],
                    'subdependencies': json.loads(row[4]) if row[4] else [],
                    'vulnerability_count': row[5],
                    'vulnerabilities': json.loads(row[6]) if row[6] else {},
                    'skipped_dependencies': json.loads(row[7]) if row[7] else [],
                    'intelligence_report': json.loads(row[8]) if row[8] else None,
                    'user_id': row[9],
                    'package_health_issues': json.loads(row[10]) if row[10] else None
                }
            return None
        except Exception as e:
            print(f"❌ Error retrieving scan result for {scan_id}: {e}")
            return None
        finally:
            conn.close()

    def get_recent_scans(self, hours: int = 24) -> list:
        """Return a list of recent scan results from the last N hours."""
        import json
        from datetime import datetime, timedelta
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        since = (datetime.now() - timedelta(hours=hours)).isoformat()
        cursor.execute('''
            SELECT scan_id, timestamp, filename
            FROM scan_results
            WHERE timestamp >= ?
            ORDER BY timestamp DESC
        ''', (since,))
        scans = []
        for row in cursor.fetchall():
            scan_id, timestamp, filename = row
            scans.append({
                'scan_id': scan_id,
                'timestamp': timestamp,
                'filename': filename
            })
        conn.close()
        return scans 

    def clear_old_scan_results(self, hours: int = 24):
        """Clear scan results older than the specified hours. If hours=0, clear all."""
        import json
        from datetime import datetime, timedelta
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        if hours > 0:
            since = (datetime.now() - timedelta(hours=hours)).isoformat()
            cursor.execute('DELETE FROM scan_results WHERE timestamp < ?', (since,))
            print(f"🗑️ Cleared scan results older than {hours} hours")
        else:
            cursor.execute('DELETE FROM scan_results')
            print("🗑️ Cleared all scan results")
        conn.commit()
        conn.close()

    def clear_all_scan_results(self):
        """Clear all scan results from the database, but preserve GitHub enrichment data"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get count of scan results before deletion
        cursor.execute('SELECT COUNT(*) FROM scan_results')
        scan_count = cursor.fetchone()[0]
        
        # Only delete scan results, preserve GitHub enrichment data
        cursor.execute('DELETE FROM scan_results')
        conn.commit()
        conn.close()
        print(f"🗑️ Cleared {scan_count} scan results (GitHub enrichment data preserved)")
    
    def clear_all_data(self):
        """Completely clear all data and recreate database with fresh schema"""
        import os
        
        print("🗑️ Clearing all database data...")
        
        # Clear all data from existing database
        self.clear_cache()
        self.clear_all_scan_results()
        
        # Close database connection
        conn = sqlite3.connect(self.db_path)
        conn.close()
        
        # Delete the database file completely
        if os.path.exists(self.db_path):
            os.remove(self.db_path)
            print(f"🗑️ Deleted database file: {self.db_path}")
        
        # Recreate database with fresh schema
        print("🔄 Recreating database with fresh schema...")
        self.init_database()
        
        print("✅ Database completely cleared and recreated successfully!")
        print(f"📁 New database location: {self.get_database_path()}")
        
        # Show initial stats
        stats = self.get_database_stats()
        print(f"📊 Fresh database stats:")
        print(f"   - Vulnerabilities: {stats['vulnerability_count']}")
        print(f"   - Cached packages: {stats['cached_packages']}")
        print(f"   - Database size: {stats['database_size_bytes']} bytes")
    
    def save_github_enrichment(self, scan_id: str, package_name: str, github_data: Dict):
        """Save GitHub enrichment data for a package"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO github_enrichment 
                (scan_id, package_name, platform, repo_path, repo_url, description, 
                 stars, forks, open_issues, closed_issues, language, last_updated, health_data)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                scan_id,
                package_name,
                github_data.get('platform'),
                github_data.get('full_name'),
                github_data.get('html_url'),
                github_data.get('description'),
                github_data.get('stargazers_count', 0),
                github_data.get('forks_count', 0),
                github_data.get('open_issues_count', 0),
                github_data.get('closed_issues_count', 0),
                github_data.get('language'),
                github_data.get('pushed_at'),
                json.dumps(github_data.get('health', {}))
            ))
            conn.commit()
        except Exception as e:
            print(f"❌ Error saving GitHub enrichment for {package_name}: {e}")
        finally:
            conn.close()
    
    def get_github_enrichment(self, scan_id: str, package_name: str) -> Optional[Dict]:
        """Get GitHub enrichment data for a package"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                SELECT platform, repo_path, repo_url, description, stars, forks, 
                       open_issues, closed_issues, language, last_updated, health_data
                FROM github_enrichment 
                WHERE scan_id = ? AND package_name = ?
            ''', (scan_id, package_name))
            
            row = cursor.fetchone()
            if row:
                return {
                    'platform': row[0],
                    'full_name': row[1],
                    'html_url': row[2],
                    'description': row[3],
                    'stargazers_count': row[4],
                    'forks_count': row[5],
                    'open_issues_count': row[6],
                    'closed_issues_count': row[7],
                    'language': row[8],
                    'pushed_at': row[9],
                    'health': json.loads(row[10]) if row[10] else {}
                }
            return None
        except Exception as e:
            print(f"❌ Error retrieving GitHub enrichment for {package_name}: {e}")
            return None
        finally:
            conn.close()
    
    def get_all_github_enrichment(self, scan_id: str) -> Dict[str, Dict]:
        """Get all GitHub enrichment data for a scan"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                SELECT package_name, platform, repo_path, repo_url, description, 
                       stars, forks, open_issues, closed_issues, language, last_updated, health_data
                FROM github_enrichment 
                WHERE scan_id = ?
            ''', (scan_id,))
            
            results = {}
            for row in cursor.fetchall():
                results[row[0]] = {
                    'platform': row[1],
                    'full_name': row[2],
                    'html_url': row[3],
                    'description': row[4],
                    'stargazers_count': row[5],
                    'forks_count': row[6],
                    'open_issues_count': row[7],
                    'closed_issues_count': row[8],
                    'language': row[9],
                    'pushed_at': row[10],
                    'health': json.loads(row[11]) if row[11] else {}
                }
            return results
        except Exception as e:
            print(f"❌ Error retrieving GitHub enrichment for scan {scan_id}: {e}")
            return {}
        finally:
            conn.close()
    
    def get_cached_github_data(self, package_name: str) -> Optional[Dict]:
        """Get cached GitHub data for a package (case-insensitive)"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                SELECT platform, repo_path, repo_url, description, stars, forks, 
                       open_issues, closed_issues, language, last_updated, health_data, created_at
                FROM github_enrichment 
                WHERE LOWER(package_name) = LOWER(?)
                ORDER BY created_at DESC
                LIMIT 1
            ''', (package_name,))
            
            row = cursor.fetchone()
            if row:
                return {
                    'platform': row[0],
                    'full_name': row[1],
                    'html_url': row[2],
                    'description': row[3],
                    'stargazers_count': row[4],
                    'forks_count': row[5],
                    'open_issues_count': row[6],
                    'closed_issues_count': row[7],
                    'language': row[8],
                    'pushed_at': row[9],
                    'health': json.loads(row[10]) if row[10] else {},
                    'cached_at': row[11]
                }
            return None
        except Exception as e:
            print(f"❌ Error retrieving cached GitHub data for {package_name}: {e}")
            return None
        finally:
            conn.close()
    
    def is_github_cache_fresh(self, package_name: str, max_age_hours: int = 24) -> bool:
        """Check if cached GitHub data is fresh (within max_age_hours) - case-insensitive"""
        cached_data = self.get_cached_github_data(package_name)
        if not cached_data:
            return False
        
        cached_at = datetime.fromisoformat(cached_data['cached_at'])
        return datetime.now() - cached_at < timedelta(hours=max_age_hours)
    
    def cache_github_data(self, package_name: str, github_data: Dict):
        """Cache GitHub data for a package"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # Use a dummy scan_id for caching (we'll use 'cache' as scan_id)
            cursor.execute('''
                INSERT OR REPLACE INTO github_enrichment 
                (scan_id, package_name, platform, repo_path, repo_url, description, 
                 stars, forks, open_issues, closed_issues, language, last_updated, health_data)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                'cache',  # Use 'cache' as scan_id for cached data
                package_name,
                github_data.get('platform'),
                github_data.get('full_name'),
                github_data.get('html_url'),
                github_data.get('description'),
                github_data.get('stargazers_count', 0),
                github_data.get('forks_count', 0),
                github_data.get('open_issues_count', 0),
                github_data.get('closed_issues_count', 0),
                github_data.get('language'),
                github_data.get('pushed_at'),
                json.dumps(github_data.get('health', {}))
            ))
            conn.commit()
            print(f"💾 Cached GitHub data for {package_name}")
        except Exception as e:
            print(f"❌ Error caching GitHub data for {package_name}: {e}")
        finally:
            conn.close() 